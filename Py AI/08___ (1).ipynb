{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дрва на одлучување"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('UM5c_RGvgQ4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Референци:\n",
    "- [Упатство за инсталирање на потребните библиотеки и екстензии](https://docs.google.com/presentation/d/1tnoeNF_ge9KK_ovTF7xgKVB64ltuV27IPShk3ddSK5w/edit#slide=id.ga20dadbc8e_0_0)- [ID3 алгоритам](https://en.wikipedia.org/wiki/ID3_algorithm)\n",
    "- [Дрва на одлучување - Википедија](https://en.wikipedia.org/wiki/Decision_tree)\n",
    "- [Изградба на дрва на одлучување - Википедија](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "- [Ентропија во теоријата на информации](https://en.wikipedia.org/wiki/Entropy_(information_theory))\n",
    "- [Информациска придобивка](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees)\n",
    "- [Библиотека за машинско учење - sklearn](https://scikit-learn.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дрво на одлучување е граф со дрвенеста структура каде секој јазол е прашање кое го дели на неколку дела даденото множество податоци. Врските во дрвото се одговорите на прашањето поставено од јазолот. Листовите на дрвото се излезите кои ќе ги произведе дрвото за даден влезен податок. \n",
    "\n",
    "Дрвото на одлучување ги класифицира дадените влезни податоци така што ќе започне од коренот и одејќи од јазол на јазол ќе стигне до некој лист чија вредност е излез за дадениот влезен податок.\n",
    "\n",
    "Еве пример за дрво на одлучување кое ќе ни одговори кое превозно средство да го искористиме во зависност од моменталната состојба на денот во кој се наоѓаме.\n",
    "\n",
    "![Пример за дрво на одлучување](images/decision_tree_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ова дрво го создаваме со помош на податоци со кои располагаме. Нека, на пример, пред нас ја имаме дадената табела од последните 12 дена. Од оваа табела може да биде создадено даденото дрво на одлучување."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [['Sun', 44, True, 'Walk'],\n",
    "     ['Sun', 23, False, 'Bus'],\n",
    "     ['Sun', 31, True, 'Walk'],\n",
    "     ['Sun', 7, False, 'Bus'],\n",
    "     ['Sun', 19, True, 'Bus'],\n",
    "     ['Cloud', 34, True, 'Walk'],\n",
    "     ['Cloud', 16, False, 'Bus'],\n",
    "     ['Cloud', 6, True, 'Walk'],\n",
    "     ['Cloud', 25, True, 'Walk'],\n",
    "     ['Cloud', 71, False, 'Bus'],\n",
    "     ['Rain', 12, False, 'Bus'],\n",
    "     ['Rain', 34, True, 'Bus']], columns=['Wheather', 'Time', 'Hungry', 'Transport'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создавање дрво на одлучување\n",
    "\n",
    "Основниот алгоритам за создавање дрво на одлучување е [ID3](https://en.wikipedia.org/wiki/ID3_algorithm). Алгоритамот го гради дрвото од коренот кон листовите и притоа користи алчен пристап. \n",
    "Накратко, алгоритамот оди вака:\n",
    "*  Одреди која карактеристика најдобро го дели множеството.\n",
    "*  Означи ја таа карактеристика како јазол.\n",
    "*  За секоја можна вредност на одбраната карактеристика ќе создадеме нов јазол кој ќе биде дете на моменталниот јазол.\n",
    "*  Податоците кои ги имаме за моменталниот јазол ќе ги поделиме на сите негови деца според вредноста на одбраната карактеристика.\n",
    "*  Ако новокреираните табели со дадените податоци се перфектно класифицирани, запираме, инаку истиот алгоритам го повторуваме за секој новокреиран јазол.\n",
    "\n",
    "Главно прашање е како да одредиме која карактеристика е најдобра за да го подели множеството. За алгоритамот ID3 најдобра карактеристика е онаа која има најголема [информациска придобивка](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees). Оваа придобивка ја сметаме како мерка која ќе измери колку добро карактеристиката го дели множеството на групи за да можеме успешно да класифицираме. \n",
    "\n",
    "Алгоритамот е алчен бидејќи секогаш ја одбира најдобрата поделба само за момнеталната распределба на податоците, а не ја гледа најдобрата можност генерално за целото дрво.\n",
    "\n",
    "Алгоритамот подразбира дека сите карактеристики се дискретни, а класификацијата е бинарна. \n",
    "\n",
    "### Информациска придобивка\n",
    "\n",
    "Информациската придобивка е статистичка мерка која кажува колку добро карактеристиката го дели множеството на групи за да можеме успешно да класифицираме. На сликата (десно) може да видиме како една карактеристика го дели множеството на два дела. Двата дела имаат приближно еднаков број `+` и `-`. Едноставно, оваа поделба не нѐ води поблиску кон успешна класификација бидејќи подгрупите се хомогени. За разлика од ова, (лево) ја имаме карактеристиката со голема информациска придобивка која подобро го дели множеството бидејќи има изразена нехомогеност. Лесно забележуваме дека во едната подгрупа имаме повеќе `+`, а во другата имаме повеќе `-`. Ова нѐ води кон успешна класификација.\n",
    "\n",
    "![Висока информациска придобивка](images/high_information_gain.png) \n",
    "![Ниска информациска придобивка](images/low_information_gain.png) \n",
    "\n",
    "Пред да ја дефинираме точно информациската придобивка, ќе дефинираме што значи [ентропија](https://en.wikipedia.org/wiki/Entropy_(information_theory) во теоријата на инфромации. \n",
    "\n",
    "#### Ентропија\n",
    "\n",
    "Генерално, ентропијата е мерка за неред во едно множество. За нашиот проблем ентропијата ќе ни каже дали во едно многжество податоци, како претходно со `+` и `-`, имаме хомогеност или пак не. Ентропијата $H$ во теоријата на информации ја пресметуваме според равенката на научникот [Клод Шенон](https://en.wikipedia.org/wiki/Claude_Shannon)\n",
    "\n",
    "$$ H = \\sum_i - p_i \\log p_i$$\n",
    "\n",
    "За алгоритамот ID3, неговата бинарна класификација, и дадено множество $S$ каде излезите се означени со `+` и `-`, ентропијата ќе ја запишуваме како\n",
    "\n",
    "$$ H(S) = - p_+ \\log_2 p_+ - p_- \\log_2 p_- $$\n",
    "\n",
    "каде $p_+$ е подмножеството на $S$ каде излезот е `+`, а $p_-$ е подмножеството на $S$ каде излезот е `-`.\n",
    "\n",
    "Вредноста која ќе ја добиеме е реален број. На пример, за 30 податоци каде 14 се `+`, а 16 се `-`, ќе добиеме дека ентропијата е 0.996. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy(a, b):\n",
    "    \"\"\"\n",
    "    Function that calculates information entropy.\n",
    "    :param a: subset A size\n",
    "    :param b: subset B size\n",
    "    :returns: entropy\n",
    "    \"\"\"\n",
    "    if a == 0 or b == 0:\n",
    "        return 0   \n",
    "                            #idejata e ako imas 15 plusa i 0 minusi na primer, entropijata e minimalna, neredot e minimalen; taa e max koga imame ednakov broj plusevi i minusi\n",
    "    m = a + b\n",
    "    return - a/m * np.log2(a/m) - b/m * np.log2(b/m)\n",
    "\n",
    "entropy(14, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во зависност од бројот на `+` и `-` можеме да исцртаме график. Графикот ќе го исцртаме за 100 точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.linspace(start=0, stop=1, num=100)\n",
    "y = np.array([entropy(p, 1-p) for p in x])\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "fig = go.Figure(go.Scatter(x=x, y=y))\n",
    "fig.update_layout(title='Ентропија за дадено множество', xaxis_title='p+ or p-', yaxis_title='H(S)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Од тука можеме да видиме дека ентропијата е 0 ако сите податоци од едно множество припаѓаат на една класа. Најголема е кога има ист број податоци од двете класи.\n",
    "\n",
    "#### Духовита претстава на ентропијата според Стефан :D\n",
    "\n",
    "Нека имаме $N$ гости. Ги прашуваме кој сака да пие пиво и ги класифицираме гостите во две групи: (1) пие пиво и (2) не пие пиво. Земаме одговор од секој од гостите и одиме во кујната. Таму ни се поставува прашањето \"Кој рече дека ќе пие пиво?\".\n",
    "*  Најлесно е да запаметиме ако никој не пие пиво или пак сите ќе пијат.\n",
    "*  Лесно е да запаметиме ако само еден нарачал пиво. Подеднакво лесно е да запаметиме ако само еден __не__ нерачал пиво.\n",
    "*  Малку потешко е ако треба да запаметиме дека двајца ќе пијат пиво. Подеднакво тешко е ако треба да запаметиме дека двајца __нема__ да пијат пиво.\n",
    "*  Уште малку потешко е ако треба да запаметиме дека тројца ќе пијат пиво. Подеднакво тешко е ако треба да запаметиме дека тројца __нема__ да пијат пиво.\n",
    "*  ...\n",
    "*  ...\n",
    "*  ...\n",
    "*  Најтешко е да запаметиме кои личности ќе пијат, а кои не, ако точно половина пијат, а другата половина не.\n",
    "\n",
    "Всушност, она што треба да запаметиме е информацијата која ја носи анкетата направена врз гостите. Одговорите на гостите можеме да ги сметаме како стохастички извор на податоци. Ако секоја вечер ја правиме оваа анкета ќе добиеме распределба како на графикот горе. Ова е ентропијата.\n",
    "\n",
    "Имајќи го предвид овој пример, многу полесно ќе ја разберете првата реченица на википедија која опишува што е [ентропија](https://en.wikipedia.org/wiki/Entropy_(information_theory)), цитирана подолу.\n",
    "\n",
    "`Information entropy is the average rate at which information is produced by a stochastic source of data.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да се вратиме на алгоритамот ID3. Споменавме дека овој алгоритам за најдобра карактеристика ја одбира онаа која има најголема информациска придобивка. По трети пат, таа е мерка која ќе измери колку добро дадена карактеристика $a$ го дели множеството $S$ на групи за да можеме успешно да класифицираме. Генерално, ќе ја изразиме како разлика помеѓу моменталната ентропија на множеството $S$ и ентропијата која ќе ја пресметаме откако карактеристиката $a$ ќе го подели множеството на групи.\n",
    "\n",
    "$$ IG(S, a) = H(S) - H(S|a) $$\n",
    "\n",
    "Попрецизно ќе запишеме\n",
    "\n",
    "$$ IG(S, a) = H(S) - \\sum_v \\frac{|S_a(v)|}{|S|} H(S_a(v)) $$\n",
    "\n",
    "Тука $v$ е вредност на карактеристиката $a$ која го дели множеството на повеќе подмножества. Подмножеството на множеството $S$ за вредноста $v$ на карактеристиката $a$ го означуваме како $S_a(v)$. Ентропијата $H(S|a)$ откако $a$ ќе ги подели множеството ја пресметуваме како среднa вредност од ентропиите посебно пресметани за секоја вредност $v$ на карактеристиката $a$. Тие ентропии се помножени со тежински множител $\\frac{|S_a(v)|}{|S|}$ кој кажува колкав дел се податоците во $S_a(v)$ од податоците во $S$.\n",
    "\n",
    "Еве пример за дадено множество со 30 податоци од кои 14 се `+`, а 16 се `-`. Да ја пресметаме информациската придобивка.\n",
    "\n",
    "![Информациска придобивка](images/information_gain.png)\n",
    "\n",
    "Левото подмножество има 17 податоци, од кои 13 се `+`, а 4 се `-`. Тежинскиот множител ќе биде $\\frac{17}{30}$. Ентропијата ќе ја пресметаме според функцијата `entropy()`со која веќе располагаме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h1 = entropy(13, 4)\n",
    "h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Десното подмножество има 13 податоци, од кои 1 е `+`, а 12 се `-`. Тежинскиот множител ќе биде $\\frac{13}{30}$. Ентропијата ќе ја пресметаме според функцијата `entropy()`со која веќе располагаме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h2 = entropy(1, 12)\n",
    "h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ентропијата на дадено множество веќе ја пресметавме погоре, но ќе ја пресметаму пак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_before_split = entropy(14, 16)\n",
    "h_before_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ентропијата $H(S|a)$ ќе ја пресметаме според дадената равенка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_after_split = 17/30 * h1 + 13/30 * h2\n",
    "h_after_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За крај, ќе ја пресметаме информациската придобивка. Добиваме дека за оваа поделба на карактеристиката $a$ имаме информациска придобивка од 0.38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "information_gain = h_before_split - h_after_split\n",
    "information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ајде да пресметаме која карактеристика од `wheather`, `time` или пак `hungry` најдобро го дели множеството запишано во променливата `df` на почетокот на оваа дигитална тетратка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 алгоритамот смета дека карактеристиките имаат дискретни вредности. \n",
    "*  `Wheather` има три различни вредности и тоа е во ред. \n",
    "*  `Hungry` има две различни вредности и тоа е во ред.\n",
    "*  `Time` има многу различни вредности. Можеме да ги оставиме така, ама пологично е да направеме како што беше однапред предложено, да поставиме граница од 30 минути и да сметаме за сите податоци дали вреемто е над или под 30 минути. Всушност, така е и конструирано дрвото на одлучување дадено на почетокот на тетратака. Ќе поставиме нова колона Time_over_30 и ќе ја пополниме со `True` или `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vo df napravi nova kolona od Time kolonata, vo koja kje stoi dali podatocite ispolnuvaat uslov da imaat vrednost >30 ili ne (VRAKJA TRUE/FALSE)\n",
    "#najlesno e kompjuterot da raboti so podatoci sto gi razbira odnosno so edinici i so nuli\n",
    "df['Time_over_30'] = df['Time'] > 30\n",
    "# оваа редица служи за подредување на колоните бидејќи најлогично е излезната колона Transport да ни е најдесно.\n",
    "df = df[['Wheather', 'Time', 'Time_over_30', 'Hungry', 'Transport']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега ќе дефинираме нова функција која ќе ја пресмета информациската придобивка за дадено множество податоци. Оваа функција ќе ја користиме за пресметка на ентропијата на подмножествата податоци кога некоја карактеристика ќе го подели множеството."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ODGOVOR MOJ: VEROJATNO TOA E MOMENTOT DEKA OVA E ENTROPIJATA PRED PODELBA, IMAME MNOZESTVO PODATOCI OD KOI NEKOI DAVAAT OUTPUT BUS NEKOI WALK, E SEGA AKO IMAME KARAKTERISTIKA KOJA\n",
    "SOVRSENO KE JA NAPRAVI PODELBATA BUS/WALK DA BIDE NEJZINIOT ODGOVOR CIST SAMO SO BUS ILI SAMO SO WALK TOGAS ZBORUVAME ZA SOVRSENA PODELBA\n",
    "!!!!!!!!!!!!!!!!Prasanje za Stefan: koja e logikata da proveruvam dali e dobra podelbata spored samiot output koga idejata e so podobra podelba da stignam do nego? ili samo ilustrativno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy_of_dataset(df, output_column, class_1, class_2):\n",
    "    \n",
    "#     ги земаме податоците од множеството df каде излезот е еднаков на класа 1\n",
    "    class_1_data = df.query(f\"{output_column} == '{class_1}'\")\n",
    "    \n",
    "#     ги земаме податоците од множеството df каде излезот е еднаков на класа 2\n",
    "    class_2_data = df.query(f\"{output_column} == '{class_2}'\")\n",
    "    \n",
    "# ја пресметуваме ентропијата за даденото множество податоци\n",
    "    return entropy(class_1_data.shape[0], class_2_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Значи имам едно големо множество податоци. Избирам да го поделам според тоа дали излезот е пеш или автобус. \n",
    "Ја поделувам табелата на две табели: едната што ги содржи тие редови во кои за соодветни податоци излезот е пеш и втора во која излезот за соодветни податоци е автобус.\n",
    "За да ја пресметам ентропијата, треба да видам колку редици се со едниот, а колку со другиот излез.\n",
    "Со оглед на тоа што при поделбата на табелата таа пак се дели на табели, табелите имаат редици и колони, па бројот на редици ќе го извлечам од tabelata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Најдобрата карактеристика е онаа која има најголема информациска придобивка. Ќе ја пресметаме информациската придобивка за сите карактеристики и ќе одлучиме која е најдобра споредувајќи ги. Но, пред тоа треба да ја пресметаме ентропијата на даденото множество податоци."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_column = 'Transport'\n",
    "#tuka sig bi bilo soodvetno i true false za bus/walk da izbereme edno\n",
    "class_1 = 'Bus'\n",
    "class_2 = 'Walk'\n",
    "\n",
    "#se povikuva na pogore definiranata funkcija, koja sto za pratenite parametri celata tabela ja deli na podmnozestva zavisno od nivnoto ispolnuvanje na uslovot class_1 ili class_2\n",
    "h_before_split = entropy_of_dataset(df, output_column, class_1, class_2)\n",
    "h_before_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Карактеристиката `Wheather` има 3 различни вредности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Pravam proverka kakva podelba kje napravi karakteristikata Wheather; znaci sega za sega podatocite ne se podeleni i imaat entropija 0.9 sto e mnogu losa vrednost za entropija, a skoro sovrsena vrednost za informaciska pridobivka\n",
    "\n",
    "\n",
    "#Tuka samo ja pravam podelbata spored prasanje WHEATHER\n",
    "sun_data=df.query(\"Wheather=='Sun'\")\n",
    "cloud_data = df.query(\"Wheather == 'Cloud'\")\n",
    "rain_data = df.query(\"Wheather == 'Rain'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sun_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cloud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vo ovoj moment imam 3 tabeli soglasno na toa sto imam 3 razlicni odgovori na prasanjeto Wheather. So ogled na toa sto output-ot od celiot prasalnik mi e Bus/Walk, vo sekoja od trite tabeli proveruvam kakva e raspredelbata \n",
    "#na Bus/Walk vo ovie tri tabeli\n",
    "\n",
    "\n",
    "#pa povikuvam entropija od sun_data, entropija od tabelata cloud_data i entropija od tabelata rain_data vo odnos na izlez Transport i odgovori Bus i Walk\n",
    "\n",
    "\n",
    "#so ogled na toa sto vo tabela 3 (rain_data) gledam deka imam isklucitelno samo Bus kako odgovor tuka entropijata e entropija(2,0)=0 a ovie 2 i nula gi vlece eve vaka     return entropy(class_1_data.shape[0], class_2_data.shape[0])\n",
    "def entropy_of_dataset(df, output_column, class_1, class_2):\n",
    "    \n",
    "#     ги земаме податоците од множеството df каде излезот е еднаков на класа 1\n",
    "    class_1_data = df.query(f\"{output_column} == '{class_1}'\")\n",
    "    \n",
    "#     ги земаме податоците од множеството df каде излезот е еднаков на класа 2\n",
    "    class_2_data = df.query(f\"{output_column} == '{class_2}'\")\n",
    "    \n",
    "# ја пресметуваме ентропијата за даденото множество податоци\n",
    "    return class_2_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_sun_data=entropy_of_dataset(sun_data, output_column, class_1, class_2)\n",
    "h_sun_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sun_data = df.query(\"Wheather == 'Sun'\")\n",
    "\n",
    "cloud_data = df.query(\"Wheather == 'Cloud'\")\n",
    "\n",
    "rain_data = df.query(\"Wheather == 'Rain'\")\n",
    "\n",
    "\n",
    "h_sun_data = entropy_of_dataset(sun_data, output_column, class_1, class_2)\n",
    "h_cloud_data = entropy_of_dataset(cloud_data, output_column, class_1, class_2)\n",
    "h_rain_data = entropy_of_dataset(rain_data, output_column, class_1, class_2)\n",
    "\n",
    "#print('h_sun_data', h_sun_data)\n",
    "#print('h_cloud_data', h_cloud_data)\n",
    "#print('h_rain_data', h_rain_data)\n",
    "#print()\n",
    "\n",
    "factor_sun_data = sun_data.shape[0] / df.shape[0]\n",
    "factor_cloud_data = cloud_data.shape[0] / df.shape[0]\n",
    "factor_rain_data = rain_data.shape[0] / df.shape[0]\n",
    "\n",
    "h_after_split_wheather = float(factor_sun_data) * float(h_sun_data) + float(factor_cloud_data) * float(h_cloud_data) + float(factor_rain_data) * float(h_rain_data)\n",
    "information_gain_wheather = h_before_split - h_after_split_wheather\n",
    "\n",
    "#print('h_after_split_wheather', h_after_split_wheather)\n",
    "print('information_gain_wheather', information_gain_wheather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Карактеристиката `Time_over_30` има 2 различни вредности."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Od ovie dve razlicni vrednosti ni trebaat dve tabeli, ednata vo koja e nadminato vremeto od 30 min, a drugata vo koja ne e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_under_30_data = df.query(\"Time_over_30 == False\")\n",
    "time_under_30_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_over_30_data = df.query(\"Time_over_30 == True\")\n",
    "time_under_30_data = df.query(\"Time_over_30 == False\")\n",
    "\n",
    "\n",
    "#entropijata se povikuva na dvete mnozestva, kadesto se pravi proverkata kolku se plusevi a kolku minusi (preku ovaa proverka dali se namalila homogenosta dovolno dobro)\n",
    "#odnosno dali se iscisteni podatocite so koi raspolagame vo odnos na output-ot\n",
    "h_time_over_30_data = entropy_of_dataset(time_over_30_data, output_column, class_1, class_2)\n",
    "h_time_under_30_data = entropy_of_dataset(time_under_30_data, output_column, class_1, class_2)\n",
    "\n",
    "print('h_time_over_30_data', h_time_over_30_data)\n",
    "print('h_time_under_30_data', h_time_under_30_data)\n",
    "print()\n",
    "\n",
    "\n",
    "#faktorot so koj kje vlijae entropijata za over30 e kolku istanci vleguvaat vo over30 (sto kaj mene e x=((a+)+(b))/vkupniot broj istanci koisto se podeleni niz procesot (sto kaj mene e m)\n",
    "factor_time_over_30_data = time_over_30_data.shape[0] / df.shape[0]\n",
    "factor_time_under_30_data = time_under_30_data.shape[0] / df.shape[0]\n",
    "\n",
    "h_after_split_time_30 = factor_time_over_30_data * h_time_over_30_data + factor_time_under_30_data * h_time_under_30_data\n",
    "information_gain_time_30 = h_before_split - h_after_split_time_30\n",
    "\n",
    "print('h_after_split_time_30', h_after_split_time_30)\n",
    "print('information_gain_time_30', information_gain_time_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Карактеристиката `Hungry` има 2 различни вредности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hungry_data = df.query(\"Hungry == True\")\n",
    "hungry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungry_data = df.query(\"Hungry == True\")\n",
    "not_hungry_data = df.query(\"Hungry == False\")\n",
    "\n",
    "h_hungry_data = entropy_of_dataset(hungry_data, output_column, class_1, class_2)\n",
    "h_not_hungry_data = entropy_of_dataset(not_hungry_data, output_column, class_1, class_2)\n",
    "\n",
    "print('h_hungry_data', h_hungry_data)\n",
    "print('h_not_hungry_data', h_not_hungry_data)\n",
    "print()\n",
    "\n",
    "factor_hungry_data = hungry_data.shape[0] / df.shape[0]\n",
    "factor_not_hungry_data = not_hungry_data.shape[0] / df.shape[0]\n",
    "\n",
    "h_after_split_hungry = factor_hungry_data * h_hungry_data + factor_not_hungry_data * h_not_hungry_data\n",
    "information_gain_hungry = h_before_split - h_after_split_hungry\n",
    "\n",
    "print('h_after_split_hungry', h_after_split_hungry)\n",
    "print('information_gain_hungry', information_gain_hungry)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "znaci otkako ednas kje bidat podeleni najdobro spored hungry, posle kje proverime vaka podelenite podatoci dali podobro gi deli wheather na primer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заклучуваме дека најголема информациска придобивка има карактеристиката `Hungry`, па таа ја земаме како прво прашање во нашето стебло на одлучување. Понатаму го решаваме истиот проблем посебно за секое подмножество на карактеристиката `Hungry`: `True` или`False` и бараме која карактеристика најдобро ќе ги подели нив."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача за самостојна работа:\n",
    "\n",
    "- Имплементирајте го алгоритамот ID3 за целото податочно множество и создадете го дрвото."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дрва на одлучување преку библиотеката `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris #datasets e modul na bibliotekata scikit-learn kojsto ja dava funkcijata load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=load_iris()                                #vo data go zapisiuvame vcitanoto mnozestvo podatoci od load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Како податочно множество ќе ги користиме една збирка податоци за перуники. Оваа збирка податоци многу често се користи како множество податоци за испитување на алгоритми за машинско учење, особено за почетници во оваа област. Затоа оваа збирка податоци е дел од библиотеката `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Перуники](images/iris.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "                                                        #load_iris se sostoi od:\n",
    "                                                        #data, \n",
    "                                                        #target (0-setosa, 1-versicolor, 2-virginica), se sostoi samo od integers\n",
    "                                                        #target_names (setosa, versicolor, virginica), zacuvani vo lista\n",
    "                                                        #feature_names (sepal length, sepal width, petal length, petal width) \n",
    "                                                        \n",
    "print('Classes to predict: ', data.target_names)\n",
    "                                                        #spored pratenite karakteristiki treha da predvidi dali cvekjeto e setosa, versicolor ili virginica \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моментално податоците за наоѓаат во променливата `data` која е збирка од податоци, а ние треба соодветно да ги извадиме податоците."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target\n",
    "print('Number of examples in the data:', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да видиме како изгледаат податоците. Има 4 карактеристики кои се измерени должини на цвеќењето."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x                                                       #data e struktura sto gi prevzemala site podatoci od load_iris, a vo load_iris data go oznacuva mnozestvoto podatoci-lista od listi \n",
    "                                                        #kadesto sekoja od listite ima po 4 podatoci koisto soodvetno oznacuvaat sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y                                                       #target e del od load_iris i toj ni dava izlez integer sto ni go oznacuva soodvetniot tip na cvet (spored pratenite karakteristiki)\n",
    "                                                        #pa taka ako y=0 pristo y=f(x), toa znaci deka listata 4 karakteristiki sto gi imame prateno soodvetstvuvaat na cvetot so oznaka 0 sto e setosa "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sakam da ja dobijam izvornata tabela, ova zavrsi go pred kolokviumska.\n",
    "z=data.feature_names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def create_table(data, headers):\n",
    "    table = PrettyTable()\n",
    "    \n",
    "    # Set the column headers\n",
    "    table.field_names = headers\n",
    "    \n",
    "    # Add data to the table\n",
    "    for row in data:\n",
    "        table.add_row(row)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "table = create_table(x, z)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "table['Output']=data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ќе го поделиме множеството на множество за тренирање и множество за тестирање. Ќе тренираме на `X_train` и `y_train`, ќе погодуваме на `X_test`, а резултатите ќе ги споредуваме со `y_test`. Библиотеката има веќе готова функција за делење на множеството на овој начин, а ние само треба да кажеме колкав процент сакаме да биде множество за тренирање, а колкав процент да биде множество за тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                                                                                                #znaci se sluzime so funkcijata train_test_split od soodvetnata buiblioteka\n",
    "                                                                                                #vo dve razlicni listi ni se vlezovite i izlezite \n",
    "                                                                                                #x_train i x_test ni se karakteristikite na cvetot. del od tie karakteristiki kje bidat dadeni za treniranje vrz niv, a del za trst\n",
    "                                                                                                #analogno i za y_train i y_test kadesto ni se izlezite vo odnos na karakteristikite pritoa vnimavaj, sekako mora za sekoj vlez da ima izlezi\n",
    "                                                                                                #random_state ako go zadademe na fiksna vrednost kje ni garantira deka podatocite kje bidat na isti nacin podeleni sekogas koga kje se izvrsuva kodot\n",
    "                                                                                                #155 ne vlijae na rezultatite i moze da prima bilo koja nenegativna vrednost\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=155, test_size=0.25)\n",
    "                                                                                                #test_size kazuva kolkav del od kodot kje bide za testiranje, ostanatiot e za treniranje vrz nego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Го создаваме класификаторот. Аргументите кои можете да ги испратите ќе ги погледнете во документацијата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy')                                             #DecisionTreeClassifier e klasa sto implementira algoritam so drvo na odlucuvanje\n",
    "                                                                                                #se sostoi od 1.splitting criteria (gini/entrophy, pa bidejkji e predefinirano na gini, morame da pratime kako argument da raboti so entropija)\n",
    "                                                                                                #rekurzivno delenje, leaf nodes i prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со функцијата `fit()` му ги даваме податоците за тренирање на класификаторот за да тренира на нив. Тој во себе ќе го изгради дрвото на одлучување, а потоа ние ќе можеме д аго предвидиме излезот за нови податоци.\n",
    "THE IDEA IS TO CREATE A TREE THAT GENERALIZES WELL TO NEW INSTANCES BY EFFECTIVELY CAPTURING THE UNDERLYING PATTERNS IN THE TRAINING DATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                                                                                #na vekje kreiraniot klasifikator mu davame podatoci na koi treba da trenira i nivni soodvetni izlezi                                                                                                #zn\n",
    "clf.fit(x_train, y_train)\n",
    "                                                                                                #so izvrsuvanje na ovoj kod vekje klasifikatorot ne e prazen i neistreniran tuku se sostoi od nauceni informacii\n",
    "                                                                                                #od trening datata i sega vekje moze da se koristi za da pravi pretpostavki na nevideno mnozestvo podatoci"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mi treba idejata pozadi treniranjeto so podatoci preku entropija kriteriumot\n",
    "dali pozadinski kompjuterot sam im ja naogja logikata i go pravi drvoto na granenje (na primer ako uvidi deka site listovi>2cm se na prviot cvet, toa podocna da go napravi vo forma na prasanje)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откако ќе истренира класификаторот, ќе му ги пратиме податоците за тест за тој да ги предвиди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred =  clf.predict(x_test)                                                                   #na vekje istreniraniot klasifikator, mu prakjame mnozestvo podatoci na koi treba da go predvidi izlezot\n",
    "                                                                                                #predvideniot izlez e vo y_pred smesten, a nie gi imame tocnite izlezi za pratenite vlezovi vo y_test\n",
    "                                                                                                #za x_train tocen izlez e y_train\n",
    "                                                                                                #za x_test tocen izlez e y_test\n",
    "                                                                                                        #a predviden e y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred` Се предвидените податоци и треба да ги споредиме со точните. Ќе ја искористиме функцијата `accuracy_score()` за пресметка на точност на две множества податоци. Таа е дел од библиотеката `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on train data:  1.0\n",
      "Accuracy Score on test data:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "                                                                                                #slednite redovi kod sluzat za proverka na verodostojnosta na samiot klasifikator\n",
    "                                                                                                #accuracy_score gi sporeduva pretpostavenite i tocni labels za soodvetni vlezni karakteristiki pa ja vrakja proporcijata\n",
    "                                                                                                #na pogodeni istanci\n",
    "            \n",
    "                                                                                                #opsto accuracy_score(y_true, y_pred)\n",
    "                \n",
    "                                                                                                #za da proveri kolku dobro raboti na videni podatoci, za tie podatoci se povikuva predict(x_train)\n",
    "                                                                                                #pretpostavkite za tie podatoci se vnesuvaat vo y_pred\n",
    "                                                                                                #a tocnite izlezi za tie podatoci se vo y_train \n",
    "print('Accuracy Score on train data: ', accuracy_score(y_true=y_train, y_pred=clf.predict(x_train))) \n",
    "\n",
    "                                                                                                #ova ja sledi istata logika samo za nevideni podatoci\n",
    "                                                                                                #tuka y_pred=clf.predict(x_test), a tocen izlez e y_test\n",
    "print('Accuracy Score on test data: ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забележуваме дека точноста на множеството за тренирање е 1, што е својствено за дрвата на одлучување. Точноста на множеството за тест е нешто помала од 1. Ова е сосема логично бидејќи алгоритамот погодува податоци кои никогаш не ги видел."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Moze da se sluci accuracy score on train data < accuracy score on test data. Ova kje probam da go resam so pomos na izbiranje drug random_state odnosno so generiranje nova podelba na podatocite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
